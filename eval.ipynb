{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from transformers import AutoModelForMaskedLM, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model_unspervised_name = './review_generate/unsupervised/checkpoints/bart-base-cnn-rating-tokens/checkpoint-47271'\n",
    "tokenizer = AutoTokenizer.from_pretrained(gen_model_unspervised_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96411d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"sssss \", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "# dataset = 'Digital_Music_data'\n",
    "# dataset = 'Musical_Instruments_data'\n",
    "# dataset = 'Video_Games_data'\n",
    "dataset = 'Office_Products_data'\n",
    "all_df = pd.read_csv(f'dataset/{dataset}/data.csv')\n",
    "print(len(all_df))\n",
    "all_df = all_df[all_df['reviews'].notna()]\n",
    "all_df = all_df[all_df['reviews'] != '']\n",
    "\n",
    "all_df['clean_reviews'] = all_df['reviews'].apply(clean_str)\n",
    "all_df = all_df[all_df['clean_reviews'] != '']\n",
    "\n",
    "print(len(all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from utils import get_stopwords\n",
    "stop = stopwords.words('english')\n",
    "print('nltk stop ' ,len(stop))\n",
    "stop = [clean_str(s) for s in stop]\n",
    "stop = set(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews = []\n",
    "num_of_item = 0\n",
    "for item_id, item_df in all_df.groupby('item_id'):\n",
    "    num_of_item += 1\n",
    "    sample_df = item_df.sample(min(1, len(item_df)))\n",
    "    clean_reviews.extend(sample_df['reviews'].tolist())\n",
    "\n",
    "clean_reviews = [clean_str(review) for review in clean_reviews]\n",
    "print(num_of_item)\n",
    "print(len(clean_reviews))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e76df",
   "metadata": {},
   "source": [
    "### Aspect evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_aspect = 15\n",
    "aspect_df = pd.read_csv(f'aspect/data/{dataset}_{n_aspect}.csv')\n",
    "print(aspect_df.shape)\n",
    "aspect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318bfbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_vocab = []\n",
    "aspect_vocab_list = []\n",
    "topk = 30\n",
    "for i , row in aspect_df.iterrows():\n",
    "    each_aspect_words = eval(row.aspect_words)\n",
    "    each_aspect_words = each_aspect_words[:topk]\n",
    "    each_aspect_words = [clean_str(word) for word in each_aspect_words]\n",
    "    \n",
    "    filter_words = []\n",
    "    for word in each_aspect_words:\n",
    "        if len(word) > 2 and word not in stop and word != '':\n",
    "            filter_words.append(word)\n",
    "            \n",
    "    aspect_vocab_list.append(set(filter_words))\n",
    "    \n",
    "    aspect_vocab.extend(filter_words)\n",
    "print(len(aspect_vocab))\n",
    "aspect_vocab = set(aspect_vocab)\n",
    "print(len(aspect_vocab))\n",
    "print(len(aspect_vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeeacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_aspect(clean_reviews, do_print=True):\n",
    "    aspect_prob_list = []\n",
    "    has_aspect_words = 0\n",
    "    aspect_words = set()\n",
    "    for review in clean_reviews:\n",
    "        words = review.split()        \n",
    "        aspect_word_count = 0\n",
    "        for word in words:\n",
    "            if word in aspect_vocab:\n",
    "                aspect_words.add(word)\n",
    "                aspect_word_count += 1\n",
    "        if aspect_word_count > 0:\n",
    "            has_aspect_words += 1\n",
    "        if len(words) > 0:\n",
    "            aspect_prob_list.append(aspect_word_count / len(words))\n",
    "        else:\n",
    "            aspect_prob_list.append(0)\n",
    "    \n",
    "    if do_print:\n",
    "        print('aspect evaluation')\n",
    "        print('% of aspect words')\n",
    "        print(np.mean(aspect_prob_list))\n",
    "    return aspect_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39aea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_aspect(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490aa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rouge(df):\n",
    "    reviews = df['attack_reviews'].tolist()\n",
    "    reviews = [clean_str(review) for review in reviews]\n",
    "    sample_nums = 100\n",
    "    reviews = random.sample(reviews, k=sample_nums)\n",
    "\n",
    "    avg_rouge1_score = 0.0\n",
    "    avg_rouge2_score = 0.0\n",
    "    avg_rougeL_score = 0.0\n",
    "\n",
    "\n",
    "    for i in range(len(reviews)):\n",
    "        hyp = [reviews[i]] * (len(reviews) - 1)\n",
    "        ref = reviews[:i] + reviews[i + 1:]\n",
    "        rouge_scores = rouge.get_scores(hyp, ref, avg=True, ignore_empty=True)\n",
    "\n",
    "        avg_rouge1_score += rouge_scores['rouge-1']['f']\n",
    "        avg_rouge2_score += rouge_scores['rouge-2']['f']\n",
    "        avg_rougeL_score += rouge_scores['rouge-l']['f']\n",
    "\n",
    "\n",
    "    avg_rouge1_score /= sample_nums\n",
    "    avg_rouge2_score /= sample_nums    \n",
    "    avg_rougeL_score /= sample_nums \n",
    "\n",
    "    print('avg rourge1/2/L score from other generated reviews')\n",
    "    print(f'{avg_rouge1_score:.3f} / {avg_rouge2_score:.3f} / {avg_rougeL_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppl(reviews, model, tokenizer, batch_size=8, max_length=128):\n",
    "    ppl = 0.0\n",
    "    count = 0\n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        input_texts = [reviews[k] for k in range(i, i + batch_size) if k < len(reviews)]\n",
    "        encoded_input = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "        encoded_input.to(device)\n",
    "        with torch.no_grad():\n",
    "            loss = model(**encoded_input, labels=encoded_input[\"input_ids\"]).loss\n",
    "        ppl += math.exp(loss.item())\n",
    "        count += 1\n",
    "    return ppl / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "lm_pretrained_model = 'distilgpt2'\n",
    "lm_tokenizer = AutoTokenizer.from_pretrained(lm_pretrained_model, use_fast=True)\n",
    "lm_tokenizer.pad_token = lm_tokenizer.eos_token\n",
    "\n",
    "lm_model_path = 'lm/distilgpt2-Digital_Music_data_reviews/checkpoint-7731'\n",
    "\n",
    "\n",
    "if dataset == 'Musical_Instruments_data':\n",
    "    lm_model_path = './lm/distilgpt2_128-Musical_Instruments_data_reviews/checkpoint-41272'\n",
    "elif dataset == 'Video_Games_data':\n",
    "    lm_model_path = './lm/distilgpt2_128-Video_Games_data_reviews/checkpoint-59257'\n",
    "elif dataset == 'Office_Products_data':\n",
    "    lm_model_path = './lm/distilgpt2_128-Office_Products_data_reviews/checkpoint-45936'\n",
    "else:\n",
    "    print('no fine tune dataset for lm model')\n",
    "    lm_model_path = 'distilgpt2'\n",
    "print(lm_model_path)\n",
    "\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(lm_model_path).to(device)\n",
    "lm_model = lm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b421b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_length(row):\n",
    "    return len(row['attack_reviews'].strip().split())\n",
    "\n",
    "df_path = 'ATTACK_REVIEWS_OUTPUT_PATH'\n",
    "\n",
    "print(df_path)\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "df['review_words'] = df.apply(get_length, axis=1)\n",
    "df = df[df['review_words'] > 2]\n",
    "print(df['attack_ps'].mean())\n",
    "\n",
    "attack_reviews = df['attack_reviews'].tolist()\n",
    "clean_reviews = [clean_str(review) for review in attack_reviews]\n",
    "\n",
    "aspect_words = eval_aspect(clean_reviews)\n",
    "print('---')\n",
    "ppl = get_ppl(df.attack_reviews.values, lm_model, lm_tokenizer, batch_size=8, max_length=128)\n",
    "print(f'ppl')\n",
    "print('-----')\n",
    "eval_rouge(df)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
